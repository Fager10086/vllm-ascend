# 开发心得与性能优化技巧

## mask 与尾块处理

与 AscendC 的分核方式不同，每次核函数 load 和 store tensor 时都需要使用 mask，通过 mask 处理不需要计算的尾块。经 mask 处理后的 tensor shape 在每个核上相同。

## 离散地址访问

对于 `index_select` 这类取不连续地址的操作，只能循环逐行取，否则会产生大量 scalar 计算（计算二维掩码）。

## 二维 tensor 索引优化

`tl.arange` 操作对二维 tensor 的索引运算有优化。如果直接从 GM 中读取离散的行数据进行二维数组运算，会导致大量 scalar，非常耗时。

## 吃满 UB

尽量让每个 kernel 函数每次循环吃满 UB，提升性能。计算每次循环最大处理量时用 `//` 而非 `tl.cdiv`，避免 UB overflow。

## 规约方向

对于规约操作，最好按最大维度进行规约，可提升性能。

## load 与计算交织

对同一个 GM 地址多次 load 后做计算（如加法）时，建议一次 load 后做一次加法，而不是统一 load 完再计算。因为统一 load 会导致计算流水等待所有 tensor 全部 load 完成才开始计算，效率较低。

## 边计算边写入

如果有多个写入流，建议边计算边写，因为写流基本不冲突，计算完提前写入可以增大并行的可能。
